# Machine-Learning-Titanic-problem

My answer to the the Kaggle Titanic problem.

In this is I performed an EDA to find out where I needed to clean the data and after that I performed one-hot encoding.

To work out whihc featuers where the most useful I did featuer selection using The Feature importance method and another using Recursive Feature Elimination CV (RFECV).

For ML models I tested a Logistic regression classifier,Random Forest Classifier, eXtreme Gradient Boosting Classifier and k-Nearest Neighbour.

For model evaluation I compared all models using f1 score
